{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB Movie Data Exploration\n",
    "The goal of the project is to derive insights on the TMDB movie datset and perform regression models to predict revenue of the movie. This model could be leveraged by production companies for making go/no-go screening decisions.\n",
    "\n",
    "TMDB Movie Dataset available on Kaggle. Link: https://www.kaggle.com/tmdb/tmdb-movie-metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mayura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import ast\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "def text_to_dict(df):\n",
    "    for column in dict_columns: \n",
    "        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load TMDB datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tmdb_movies(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n",
    "    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)\n",
    "    return df\n",
    "\n",
    "def load_tmdb_credits(path):\n",
    "    df = pd.read_csv(path)\n",
    "    json_columns = ['cast', 'crew']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOST_COLUMNS = ['actor_1_facebook_likes','actor_2_facebook_likes','actor_3_facebook_likes','aspect_ratio',\n",
    "    'cast_total_facebook_likes','color','content_rating','director_facebook_likes', 'facenumber_in_poster',\n",
    "    'movie_facebook_likes','movie_imdb_link','num_critic_for_reviews','num_user_for_reviews']\n",
    "\n",
    "TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {'budget': 'budget','genres': 'genres','revenue': 'gross','title': 'movie_title',\n",
    "    'runtime': 'duration','original_language': 'language', 'keywords': 'plot_keywords','vote_count': 'num_voted_users'}\n",
    "\n",
    "IMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Extracting Strings from columns - nested JSON\n",
    "The Movie and credit data contain columns of nested JSON which need to be split into separate columns for accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_access(container, index_values):\n",
    "    # return missing value rather than an error upon indexing/key failure\n",
    "    result = container\n",
    "    try:\n",
    "        for idx in index_values:\n",
    "            result = result[idx]\n",
    "        return result\n",
    "    except IndexError or KeyError:\n",
    "        return pd.np.nan\n",
    "\n",
    "def get_director(crew_data):\n",
    "    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n",
    "    return safe_access(directors, [0])\n",
    "\n",
    "def pipe_flatten_names(keywords):\n",
    "    return '|'.join([x['name'] for x in keywords])\n",
    "\n",
    "def convert_to_original_format(movies, credits):\n",
    "    tmdb_movies = movies.copy()\n",
    "    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n",
    "    #tmdb_movies['year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n",
    "    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n",
    "    tmdb_movies['company'] = tmdb_movies['production_companies'].apply(lambda x: safe_access(x, [0, 'name']))\n",
    "    tmdb_movies['director'] = credits['crew'].apply(get_director)\n",
    "    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n",
    "    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n",
    "    return tmdb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math, nltk, warnings\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "pd.options.display.max_columns = 50\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "PS = nltk.stem.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#credits = load_tmdb_credits(\"tmdb_5000_credits.csv\")\n",
    "movies = load_tmdb_movies(\"movies_metadata.csv\")\n",
    "df_movies = convert_to_original_format(movies, credits)\n",
    "print('Shape:',df_movies.shape)\n",
    "\n",
    "tab_info=pd.DataFrame(df_movies.dtypes).T.rename(index={0:'column type'})\n",
    "tab_info=tab_info.append(pd.DataFrame(df_movies.isnull().sum()).T.rename(index={0:'null values'}))\n",
    "tab_info=tab_info.append(pd.DataFrame(df_movies.isnull().sum()/df_movies.shape[0]*100).T.\n",
    "                         rename(index={0:'null values (%)'}))\n",
    "tab_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2.1 Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_df = df_movies.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df['filling_factor'] = (df_movies.shape[0] \n",
    "                                - missing_df['missing_count']) / df_movies.shape[0] * 100\n",
    "missing_df.sort_values('filling_factor').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word(df, ref_col, liste):\n",
    "    keyword_count = dict()\n",
    "    for s in liste: keyword_count[s] = 0\n",
    "    for liste_keywords in df[ref_col].str.split('|'):        \n",
    "        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue        \n",
    "        for s in [s for s in liste_keywords if s in liste]: \n",
    "            if pd.notnull(s): keyword_count[s] += 1\n",
    "                \n",
    "    keyword_occurences = []\n",
    "    for k,v in keyword_count.items():\n",
    "        keyword_occurences.append([k,v])\n",
    "    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
    "    return keyword_occurences, keyword_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Genre Extraction and Analysis per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_labels = set()\n",
    "for s in df_movies['genres'].str.split('|').values:\n",
    "    g_labels = g_labels.union(set(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences, dum = word(df_movies, 'genres', g_labels)\n",
    "occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = [x for x in occurences if x[0]]\n",
    "occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"movies_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>21.9469</td>\n",
       "      <td>/rhIRbceoE9lR4veEXuwCC2wARtG.jpg</td>\n",
       "      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>17.0155</td>\n",
       "      <td>/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg</td>\n",
       "      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>11.7129</td>\n",
       "      <td>/6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg</td>\n",
       "      <td>[{'name': 'Warner Bros.', 'id': 6194}, {'name'...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>3.85949</td>\n",
       "      <td>/16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg</td>\n",
       "      <td>[{'name': 'Twentieth Century Fox Film Corporat...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>8.38752</td>\n",
       "      <td>/e64sOI48hQXyru7naBFyssKFxVd.jpg</td>\n",
       "      <td>[{'name': 'Sandollar Productions', 'id': 5842}...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview popularity  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...    21.9469   \n",
       "1  When siblings Judy and Peter discover an encha...    17.0155   \n",
       "2  A family wedding reignites the ancient feud be...    11.7129   \n",
       "3  Cheated on, mistreated and stepped on, the wom...    3.85949   \n",
       "4  Just when George Banks has recovered from his ...    8.38752   \n",
       "\n",
       "                        poster_path  \\\n",
       "0  /rhIRbceoE9lR4veEXuwCC2wARtG.jpg   \n",
       "1  /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg   \n",
       "2  /6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg   \n",
       "3  /16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg   \n",
       "4  /e64sOI48hQXyru7naBFyssKFxVd.jpg   \n",
       "\n",
       "                                production_companies  \\\n",
       "0     [{'name': 'Pixar Animation Studios', 'id': 3}]   \n",
       "1  [{'name': 'TriStar Pictures', 'id': 559}, {'na...   \n",
       "2  [{'name': 'Warner Bros.', 'id': 6194}, {'name'...   \n",
       "3  [{'name': 'Twentieth Century Fox Film Corporat...   \n",
       "4  [{'name': 'Sandollar Productions', 'id': 5842}...   \n",
       "\n",
       "                                production_countries release_date  \\\n",
       "0  [{'iso_3166_1': 'US', 'name': 'United States o...   1995-10-30   \n",
       "1  [{'iso_3166_1': 'US', 'name': 'United States o...   1995-12-15   \n",
       "2  [{'iso_3166_1': 'US', 'name': 'United States o...   1995-12-22   \n",
       "3  [{'iso_3166_1': 'US', 'name': 'United States o...   1995-12-22   \n",
       "4  [{'iso_3166_1': 'US', 'name': 'United States o...   1995-02-10   \n",
       "\n",
       "       revenue  runtime                                   spoken_languages  \\\n",
       "0  373554033.0     81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0    104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0    101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0    127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0    106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video  vote_average  vote_count  \n",
       "0                    Toy Story  False           7.7      5415.0  \n",
       "1                      Jumanji  False           6.9      2413.0  \n",
       "2             Grumpier Old Men  False           6.5        92.0  \n",
       "3            Waiting to Exhale  False           6.1        34.0  \n",
       "4  Father of the Bride Part II  False           5.7       173.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'plot_keywords'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'plot_keywords'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1bdd3e835324>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mset_keywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mliste_keywords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_movies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'plot_keywords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliste_keywords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# only happen if liste_keywords = NaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mset_keywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_keywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliste_keywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'plot_keywords'"
     ]
    }
   ],
   "source": [
    "set_keywords = set()\n",
    "for liste_keywords in df_movies['plot_keywords'].str.split('|').values:\n",
    "    if isinstance(liste_keywords, float): continue  # only happen if liste_keywords = NaN\n",
    "    set_keywords = set_keywords.union(liste_keywords)\n",
    "\n",
    "set_keywords.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_occurences, dum = word(df_movies, 'plot_keywords', set_keywords)\n",
    "keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_color(word=None, font_size=None, position=None,\n",
    "                      orientation=None, font_path=None, random_state=None):\n",
    "    h = int(200.0 * tone / 100.0)\n",
    "    s = int(200.0 * 255.0 / 100.0)\n",
    "    l = int(200.0 * float(random_state.randint(20, 70)) / 100.0)\n",
    "    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n",
    "\n",
    "fig = plt.figure(1, figsize=(18,13))\n",
    "ax1 = fig.add_subplot(2,1,1)\n",
    "\n",
    "words = dict()\n",
    "trunc_occurences = keyword_occurences[0:20]\n",
    "for s in trunc_occurences:\n",
    "    words[s[0]] = s[1]\n",
    "tone = 55.0 # define the color of the words\n",
    "\n",
    "wordcloud = WordCloud(width=1000,height=300, background_color='black', \n",
    "                      max_words=1628,relative_scaling=1,\n",
    "                      color_func = random_color,\n",
    "                      normalize_plurals=False)\n",
    "wordcloud.generate_from_frequencies(words)\n",
    "ax1.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "ax1.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(col):\n",
    "\n",
    "    # pandas series to list\n",
    "    entries = list(col)\n",
    "    \n",
    "    # handling \"|\" separator and removing duplicates\n",
    "    collect = [] #this will contain all the unique genres\n",
    "    \n",
    "    for entry in entries:\n",
    "        for _ in entry.split(\"|\"):\n",
    "            if _ not in collect:\n",
    "                collect.append(_)\n",
    "    return(collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse(df_movies['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = df_movies['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = {key:[] for key in parse(df_movies['genres'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df['year'] = year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in year: # to get genre count for each year\n",
    "    \n",
    "    #subsetting for corresponding year\n",
    "    y_df_movies = df_movies[df_movies['year'] == y]\n",
    "    \n",
    "    # converting pandas series to column\n",
    "    genres_i1 = list(y_df_movies['genres'])  \n",
    "    genres_f1 = [] # this will contain all the genres that we see for a given year(with repetition and \"|\" separator)\n",
    "    \n",
    "    for genre in genres_i1: # for splitting every entry in y_df[genres] with separator as \"|\" \n",
    "        for i in genre.split(\"|\"):\n",
    "            genres_f1.append(i)\n",
    "\n",
    "    n_list = Counter(genres_f1) # occurrence of each genre in a year\n",
    "    for genre in parse(df_movies['genres']): #this will create occurrence of each genre in a year\n",
    "        if genre not in genres_f1:\n",
    "            n_df[genre].append(0)\n",
    "        else:\n",
    "            n_df[genre].append(n_list[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.DataFrame(n_df, index = n_df['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df.columns\n",
    "del(n_df['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this dataframe shows?\n",
    "\n",
    "Let's see first row. If there are n number of movies released in 1960, then entries corresponding to 2016 shows how many times\n",
    "each genre appeared in 2016.\n",
    "Let's see this numerically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_occ = n_df.loc[2016].sum()\n",
    "total_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_occ = n_df.loc[2016,'Action']\n",
    "action_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = {key:[] for key in parse(df_movies['genres'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['year'] = year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in n_df.iterrows():\n",
    "    for genre in list(n_df.columns):\n",
    "        df1[genre].append((100*row[genre]/sum(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(df1)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df1.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df1 = df1[cols]\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top five Genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = []\n",
    "for _ in df1.columns[1:]:\n",
    "    top.append(np.mean(df1[_]))\n",
    "    top.sort(reverse = True)\n",
    "top[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = ['Drama','Comedy','Action']\n",
    "for genre in g:\n",
    "    sns.jointplot(x=df1['year'], y= df1[genre]);\n",
    "    #plot = sns.regplot(y = new_df1[genre], x = new_df1['year'], lowess = True);\n",
    "#plot.set_ylabel(\"\");\n",
    "#plot.axvline(x = 2016, color = 'black', alpha = 1.0);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3  Comparing Revenue with vote_count, popularity and runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GGPlot using rpy2 for better visual analysis.\n",
    "Here the plot analysis shows that the highly popular movies with high revenue has duration of 1hr40 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rpy2\n",
    "from plotnine import *\n",
    "# the base of rpy2 plotting is matplotlib, thus we need to declare\n",
    "# it inline in order to see the plots in the notebook\n",
    "%matplotlib inline\n",
    "# we need to activate the automatic conversion for pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ggplot(aes(x='duration', y='gross', color='num_voted_users'), data=df_movies) +\\\n",
    "    geom_point() +\\\n",
    "    theme_bw() +\\\n",
    "    xlab(\"runtime\") +\\\n",
    "    ylab(\"revenue\") +\\\n",
    "    ggtitle(\"Revenue vs runtime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ggplot(aes(x='popularity', y='gross', color='num_voted_users'), data=df_movies) +\\\n",
    "    geom_point() +\\\n",
    "    theme_bw() +\\\n",
    "    xlab(\"popularity\") +\\\n",
    "    ylab(\"gross\") +\\\n",
    "    ggtitle(\"Revenue vs popularity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot analysis shows that the top movies that have high revenue have high popularity between the frequency of 500-750 and votes from 5000-10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(aes(x='budget', y='gross', color='num_voted_users'), data=df_movies) +\\\n",
    "    geom_point() +\\\n",
    "    theme_bw() +\\\n",
    "    xlab(\"budget\") +\\\n",
    "    ylab(\"gross\") +\\\n",
    "    ggtitle(\"Revenue vs Budget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot analysis shows that the budget directly affects the revenue.\n",
    "If the movies is released with high budget the revenue is accordingly high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 10)\n",
    "#ax = sns.boxplot(x=\"open_gross\", y=\"genre\", data=df0, palette=sns.light_palette((210, 90, 60), input=\"husl\"))\n",
    "#ax = sns.boxplot(x=\"open_gross\", y=\"genre\", data=df0, palette=\"GnBu_d\")\n",
    "ax = sns.boxplot(x=\"status\", y=\"gross\", data=df_movies, palette=\"icefire\")\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"\")\n",
    "sns.despine(trim=True, left=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.4 Caluclating movies with high profit and low profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the budget of high amd low profit movie is nearly 2 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['Profit'] = df_movies['gross'] - df_movies['budget']\n",
    "X=df_movies['Profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minmax(x):\n",
    "    #use the function 'idmin' to find the index of lowest profit movie.\n",
    "    min_index = df_movies[x].idxmin()\n",
    "    #use the function 'idmax' to find the index of Highest profit movie.\n",
    "    high_index = df_movies[x].idxmax()\n",
    "    high = pd.DataFrame(df_movies.loc[high_index,:])\n",
    "    low = pd.DataFrame(df_movies.loc[min_index,:])\n",
    "    \n",
    "    #print the movie with high and low profit\n",
    "    print(\"Movie Which Has Highest \"+ x + \" : \",df_movies['original_title'][high_index])\n",
    "    print(\"Movie Which Has Lowest \"+ x + \"  : \",df_movies['original_title'][min_index])\n",
    "    return pd.concat([high,low],axis = 1)\n",
    "\n",
    "#call the find_minmax function.\n",
    "find_minmax('Profit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 Profitable Movies according to the year of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a plot which contain top 10 movies which earn highest profit.\n",
    "#sort the 'Profit' column in decending order and store it in the new dataframe,\n",
    "info = pd.DataFrame(df_movies['Profit'].sort_values(ascending = False))\n",
    "info['original_title'] = df_movies['original_title']\n",
    "data = list(map(str,(info['original_title'])))\n",
    "x = list(data[:20])\n",
    "y = list(info['Profit'][:20])\n",
    "\n",
    "#make a plot usinf pointplot for top 10 profitable movies.\n",
    "ax = sns.barplot(x=y,y=x)\n",
    "\n",
    "#setup the figure size\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "#setup the title and labels of the plot.\n",
    "ax.set_title(\"Top 20 Profitable Movies\",fontsize = 15)\n",
    "ax.set_xlabel(\"Profit\",fontsize = 13)\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x=df_movies['Profit'], y=df_movies['budget'],color='b')\n",
    "\n",
    "#setup the title and the labels of the plot.\n",
    "ax.set_title(\"Profit Vs Budget\",fontsize=13)\n",
    "ax.set_xlabel(\"Profit\",fontsize=12)\n",
    "ax.set_ylabel(\"Budget\",fontsize=12)\n",
    "\n",
    "#setup the figure size and style sheet of the plot.\n",
    "sns.set(rc={'figure.figsize':(20,7)})\n",
    "sns.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2.1 Average Movie Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(aes(x='vote_average'), data=df_movies) + \\\n",
    "    geom_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Histogram plot shows that the average TMDBscore is between 5-7.5 and the overall average is 6.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.5 Calculating movies with high and low budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['budget'] = df_movies['budget'].replace(0,np.NAN)\n",
    "find_minmax('budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(df_movies['budget'].sort_values(ascending = False))\n",
    "info['original_title'] = df_movies['original_title']\n",
    "data = list(map(str,(info['original_title'])))\n",
    "\n",
    "#extract the top 10 budget movies data from the list and dataframe.\n",
    "x = list(data[:20])\n",
    "y = list(info['budget'][:20])\n",
    "\n",
    "#plot the figure and setup the title and labels.\n",
    "ax = sns.barplot(x=y,y=x)\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "ax.set_title(\"Top 20 High Budget Movies\",fontsize = 15)\n",
    "ax.set_xlabel(\"Budget\",fontsize = 13)\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.2.6 Analysis of how runtime affect popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(df_movies['duration'].sort_values(ascending = False))\n",
    "info['popularity'] = df_movies['popularity']\n",
    "data = list(map(int,(info['popularity'])))\n",
    "\n",
    "#extract the top 10 movies with high revenue data from the list and dataframe.\n",
    "x = list(data[:20])\n",
    "y = list(info['duration'][:20])\n",
    "\n",
    "#make the point plot and setup the title and labels.\n",
    "ax = sns.pointplot(x=y,y=x)\n",
    "sns.set(rc={'figure.figsize':(25,5)})\n",
    "ax.set_title(\"Top 20 Popular Movies\",fontsize = 15)\n",
    "ax.set_xlabel(\"Runtime\",fontsize = 13)\n",
    "#sns.set_style(\"ticks\")\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that popularity of movies that have duration of about 3 hours is high and as  the duration increases the popularity decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus a movie's popluarity also depends on the duration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.7  Analysis of movie release per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['release_date'] = pd.to_datetime(df_movies['release_date'], infer_datetime_format=True)\n",
    "df_movies['release_day'] = df_movies['release_date'].apply(lambda t: t.day)\n",
    "df_movies['release_weekday'] = df_movies['release_date'].apply(lambda t: t.weekday())\n",
    "df_movies['release_month'] = df_movies['release_date'].apply(lambda t: t.month)\n",
    "\n",
    "# Year was being interpreted as future dates in some cases so I had to adjust some values\n",
    "df_movies['release_year'] = df_movies['release_date'].apply(lambda t: t.year if t.year < 2018 else t.year -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies[['release_date','release_day','release_weekday','release_month','release_year']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.countplot(df_movies.release_year)\n",
    "fig.set(ylabel='number of movies')\n",
    "for index, label in enumerate(fig.xaxis.get_ticklabels()):\n",
    "    if index % 8 != 0:\n",
    "        label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that our dataset contains movies released during the year between 2008-2016 has high number of release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_release = df_movies['release_date'].dt.month\n",
    "\n",
    "#count the movies in each month using value_counts().\n",
    "number_of_release = month_release.value_counts().sort_index()\n",
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "number_of_release = pd.DataFrame(number_of_release)\n",
    "number_of_release['month'] = months\n",
    "\n",
    "#change the column name of the new dataframe 'number_of_release'\n",
    "number_of_release.rename(columns = {'release_date':'number_of_release'},inplace=True)\n",
    "\n",
    "#plot the bar graph using plot.\n",
    "number_of_release.plot(x='month',kind='bar',fontsize = 11,figsize=(8,6))\n",
    "\n",
    "#set the labels and titles of the plot.\n",
    "plt.title('Months vs Number Of Movie Releases',fontsize = 15)\n",
    "plt.xlabel('Month',fontsize = 13)\n",
    "plt.ylabel('Number of movie releases',fontsize = 13)\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly the number of movies released during the end of the year is high between 2008-2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 ggplot analysis over popularity vs language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_movies, aes(x='popularity', fill='country')) + geom_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot explaines that Most of the movies released in English are highly popular "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Budget vs Revenue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['log_gross'] = np.log(df_movies['gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df_movies[\"budget\"].median()\n",
    "df_movies[\"budget\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_movies['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['log_budget'] = np.log(df_movies['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(aes(x = 'budget', y = 'gross'), data = df_movies) +\\\n",
    "  geom_point(alpha = 0.9, position =  \"jitter\") +\\\n",
    "  geom_smooth(method = 'lm', color = 'red') +\\\n",
    "  ylab('gross') +\\\n",
    "  xlab('budget') +\\\n",
    "    ggtitle('Budget Vs Revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(aes(x = 'log_gross', y = 'vote_average'), data = df_movies) +\\\n",
    "  geom_point(alpha = 0.9, position =  \"jitter\") +\\\n",
    "  geom_smooth(method = 'lm', color = 'red') +\\\n",
    "  ylab('tmdb score') +\\\n",
    "  xlab('gross') +\\\n",
    "   ggtitle(\"Revenue vs TMDB_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Desity Plot analysis on Budget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_movies, aes(x='budget', color='status')) + \\\n",
    "    geom_density()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(aes(x = 'log_budget', y = 'vote_average'), data = df_movies) +\\\n",
    "  geom_point(alpha = 0.9, position =  \"jitter\") +\\\n",
    "  geom_smooth(method = 'lm', color = 'red') +\\\n",
    "  ylab('TMDB_score') +\\\n",
    "  xlab('budget') +\\\n",
    "   ggtitle('TMDB score vs Budget')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(11.7, 8.27)\n",
    "corrmat = df_movies.dropna(axis=0, how='any').corr()\n",
    "\n",
    "ax = sns.heatmap(corrmat, annot=True, fmt='.2f', annot_kws={'size': 10}, center=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A barplot on Movies released in cuntry vs their popularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "dict_columns = [ 'genres', 'production_companies',\n",
    "                'production_countries', 'spoken_languages', 'keywords']\n",
    "data = text_to_dict(data)\n",
    "\n",
    "data['list_of_genres'] = list(data['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "data = data.drop(['genres'], axis=1)\n",
    "#Production_companies\n",
    "data['production_companies_names'] = list(data['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "data = data.drop(['production_companies'], axis=1)\n",
    "#production_countries\n",
    "data['production_countries_names'] = list(data['production_countries'].apply(lambda x: [i['iso_3166_1'] for i in x] if x != {} else []).values)\n",
    "data = data.drop(['production_countries'], axis=1)\n",
    "#spoken_languages\n",
    "data['spoken_languages_codes'] = list(data['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "data = data.drop(['spoken_languages'], axis=1)\n",
    "#Keywords\n",
    "data['Keyword_names'] = (data['keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "data = data.drop(['keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "#original_title\n",
    "le.fit(list(data['original_title'].fillna('')))\n",
    "data['original_title'] = le.transform(data['original_title'].fillna('').astype(str))\n",
    "#production_companies_names\n",
    "le.fit(list(data['production_companies_names'].fillna('').astype(str)))\n",
    "data['production_companies_names'] = le.transform(data['production_companies_names'].fillna('').astype(str))\n",
    "#production_countries_names\n",
    "le.fit(list(data['production_countries_names'].fillna('').astype(str)))\n",
    "data['production_countries_names'] = le.transform(data['production_countries_names'].fillna('').astype(str))\n",
    "#spoken_languages_codes\n",
    "le.fit(list(data['spoken_languages_codes'].fillna('').astype(str)))\n",
    "data['spoken_languages_codes'] = le.transform(data['spoken_languages_codes'].fillna('').astype(str))\n",
    "#Keyword_names\n",
    "le.fit(list(data['Keyword_names'].fillna('').astype(str)))\n",
    "data['Keyword_names'] = le.transform(data['Keyword_names'].fillna('').astype(str))\n",
    "#Keyword_names\n",
    "le.fit(list(data['list_of_genres'].fillna('').astype(str)))\n",
    "data['list_of_genres'] = le.transform(data['list_of_genres'].fillna('').astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['budget','popularity','runtime','revenue','list_of_genres','production_countries_names','status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = data[\"runtime\"].median()\n",
    "data[\"runtime\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data['status'])\n",
    "data = data.drop('status', axis=1)\n",
    "data = data.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_set, validation_set = train_test_split(data, test_size = 0.2, random_state = 21)\n",
    "\n",
    "#classifying the predictors and target variables as X and Y\n",
    "X_train = training_set.iloc[:,[1,2,3,4,5,6,7,8]].values\n",
    "Y_train = training_set.iloc[:,0].values\n",
    "Y_train=Y_train.astype('int')\n",
    "X_val = validation_set.iloc[:,[1,2,3,4,5,6,7,8]].values\n",
    "Y_val = validation_set.iloc[:,0].values\n",
    "Y_val=Y_val.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "X_tr_scale=scaler.fit_transform(X_train)\n",
    "X_te_scale=scaler.fit_transform(X_val)\n",
    "\n",
    "X_tr_scale[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "\n",
    "pipeline_tr = pipeline.Pipeline([ ('scaler',StandardScaler())])\n",
    "\n",
    "pipe=pipeline_tr.fit_transform(data)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b):\n",
    "    return np.sqrt(np.mean((a-b)**2))\n",
    "pd.options.display.max_columns = None\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear=LinearRegression()\n",
    "linear.fit(X_tr_scale,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=linear.predict(X_te_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse(Y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear.score(X_te_scale,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteddf = pd.DataFrame({'Actual': Y_val.flatten(), 'Predicted': y_pred.flatten()})\n",
    "predicteddf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotresult = predicteddf.head(25)\n",
    "plotresult.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_val, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_val, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_val, y_pred)\n",
    "ax.plot([Y_val.min(), Y_val.max()], [Y_val.min(),Y_val.max()], lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "param_grid = [{'n_estimators': [4, 5, 10, 20, 50]}]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "grid_search_rf = GridSearchCV(rf, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "grid_search_rf.fit(X_tr_scale, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t=grid_search_rf.predict(X_te_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse(Y_val,y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBTM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return 'rmsle', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LGBMRegressor(boosting_type='dart',num_leaves=20,max_depth=-1,min_data_in_leaf=20, learning_rate=0.2,n_estimators=500,subsample_for_bin=200000,\n",
    "                   class_weight=None,min_split_gain=0.0,min_child_weight=0.001,subsample=0.1,subsample_freq=0,colsample_bytree=0.75,reg_alpha=0.0,reg_lambda=0.0,\n",
    "                   random_state=101,n_jobs=-1)\n",
    "lr.fit(X_tr_scale, Y_train,eval_set=[(X_te_scale, Y_val)],eval_metric=rmsle,verbose=False)\n",
    "y_pred = lr.predict(X_te_scale, num_iteration=lr.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(Y_val, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_val, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_val, y_pred)))\n",
    "print('RMSLE:', rmsle(Y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_val, y_pred)\n",
    "ax.plot([Y_val.min(), Y_val.max()], [Y_val.min(), Y_val.max()], lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.score(X_te_scale,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classification Model \n",
    "\n",
    "Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_movies[['budget','gross','country','num_voted_users']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data['country'])\n",
    "data = data.drop('country', axis=1)\n",
    "data = data.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenue is classified into 4 classes based on their distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(df):\n",
    "    conditions = [\n",
    "        (df['gross'] <= 1000000),\n",
    "        (df['gross'] > 1000000) & (df['gross'] <= 25000000),\n",
    "        (df['gross'] > 25000000) & (df['gross'] <= 100000000),\n",
    "        (df['gross'] > 100000000) & (df['gross'] <= 300000000)]\n",
    "    choices=[0,1,2,3]\n",
    "    df['label']=np.select(conditions, choices, default=4)\n",
    "generate_label(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_classes = [0]*5\n",
    "for label in data['label']:\n",
    "    bin_classes[int(label)]+=1\n",
    "print(bin_classes)\n",
    "plt.bar(np.arange(5), bin_classes)\n",
    "plt.xticks(np.arange(5), np.arange(1,10))\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['gross'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"new_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(\"new_data.csv\")\n",
    "all_data = data.values\n",
    "#all_data = np.delete(all_data, [0,3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# normalize budget, release year, runtime, grosses\n",
    "normalized_values = scaler.fit_transform(all_data[:,1:7])\n",
    "# stack them together\n",
    "all_data = np.hstack((all_data[:,:1], normalized_values, all_data[:,7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_data[:, :-1], all_data[:,-1], \n",
    "            test_size=0.2, shuffle=True, random_state=418)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_classes = [0]*5\n",
    "for label in y_test:\n",
    "    bin_classes[int(label)]+=1\n",
    "print(bin_classes)\n",
    "plt.bar(np.arange(5), bin_classes)\n",
    "plt.xticks(np.arange(5), np.arange(1,10))\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_t = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_t))\n",
    "print(classification_report(y_test, y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "numNeighbors = [ 5, 10, 20, 100]\n",
    "testAcc = []\n",
    "trainAcc = []\n",
    "\n",
    "for k in numNeighbors:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n",
    "    clf.fit(x_train, y_train)\n",
    "    knn_pred = clf.predict(x_test)\n",
    "    knn_pred_train = clf.predict(x_train)\n",
    "    #print(knn_pred)\n",
    "    testAcc.append(accuracy_score(y_test, knn_pred))\n",
    "    trainAcc.append(accuracy_score(y_train,knn_pred_train))\n",
    "    print(confusion_matrix(y_test, knn_pred))\n",
    "    print(classification_report(y_test, knn_pred))\n",
    "\n",
    "plt.plot(numNeighbors, testAcc,'bv--',numNeighbors, trainAcc, 'ro--')\n",
    "plt.legend(['Test Accuracy','Train Accuacy'])\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimators = [10, 20, 50]\n",
    "testAcc = []\n",
    "trainAcc = []\n",
    "\n",
    "for k in estimators:\n",
    "    clf = RandomForestClassifier(n_estimators=k)\n",
    "    clf.fit(x_train, y_train)\n",
    "    rand_pred = clf.predict(x_test)\n",
    "    rand_pred_train = clf.predict(x_train)\n",
    "    #print(rand_pred)\n",
    "    testAcc.append(accuracy_score(y_test, rand_pred))\n",
    "    trainAcc.append(accuracy_score(y_train,rand_pred_train))\n",
    "    print(confusion_matrix(y_test, rand_pred))\n",
    "    print(classification_report(y_test, rand_pred))\n",
    "\n",
    "plt.plot(estimators, testAcc,'bv--',estimators, trainAcc, 'ro--')\n",
    "plt.legend(['Test Accuracy','Train Accuacy'])\n",
    "plt.xlabel('Estimators')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "C = [5, 20, 32, 50, 100, 500]\n",
    "\n",
    "LRtestAcc = []\n",
    "LRtrainAcc = []\n",
    "\n",
    "for param in C:\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=param, max_iter=50,activation = 'relu',solver='adam',random_state=1)\n",
    "    classifier.fit(x_train,y_train)\n",
    "    log_reg_pred_train = classifier.predict(x_train)\n",
    "    log_reg_pred = classifier.predict(x_test)\n",
    "    #print(log_reg_pred)\n",
    "    LRtestAcc.append(accuracy_score(y_test, log_reg_pred))\n",
    "    LRtrainAcc.append(accuracy_score(y_train,log_reg_pred_train))\n",
    "    print(confusion_matrix(y_test, log_reg_pred))\n",
    "    print(classification_report(y_test, log_reg_pred))\n",
    "\n",
    "    \n",
    "\n",
    "plt.plot(C, LRtestAcc,'bv--',C,LRtrainAcc,'ro--')\n",
    "plt.legend(['Test Accuracy','Train Accuracy'])\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Accuracy')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "C = [5,10,20]\n",
    " \n",
    "\n",
    "SVMLtestAcc = []\n",
    "SVMLtrainAcc = []\n",
    "\n",
    "\n",
    "\n",
    "for param in C:\n",
    "    clf = SVC(C=param,kernel='rbf',gamma='auto')\n",
    "    clf.fit(x_train,y_train)\n",
    "    svml_pred = clf.predict(x_test)\n",
    "    svml_pred_train = clf.predict(x_train)\n",
    "    #print(svml_pred)\n",
    "    SVMLtestAcc.append(accuracy_score(y_test, svml_pred))\n",
    "    SVMLtrainAcc.append(accuracy_score(y_train,svml_pred_train))\n",
    "    print(confusion_matrix(y_test, svml_pred))\n",
    "    print(classification_report(y_test, svml_pred))\n",
    "plt.plot(C, SVMLtestAcc,'ro--', C,SVMLtrainAcc,'bv--')\n",
    "plt.legend(['Test Accuracy','Train Accuracy'])\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Accuracy')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
